<html><head>
<style> table, th, td {
  border: 1px solid black;
  border-collapse: collapse;
}th {
  background: lightblue;
}</style>
</head> <body><h1>SATD</h1><table><tr><th>satd id</th> <th>satd instance id</th>  <th>project</th> <th>committer name </th> <th> Commit Hash</th> <th>old comment</th> <th>New Comment</th> <th>resolution</th> <th>Method Signature</th> <th>Method Declaration</th> <th>Method Body</th> </tr><tr><td>5431</td> <td>-1009652295</td><td>apache/hadoop</td><td>Eli Collins</td><td>a196766ea07775f18ded69bd9e8d239f8cfd3ccc</td> <td>None</td> <td>explicitly do not use \"normal\" job.setOutputPath to make sure
that it is not hardcoded anywhere in the framework.</td> <td>SATD_ADDED</td> <td>testWithLocal()</td> <td>public void testWithLocal() throws IOException, InterruptedException, ClassNotFoundException</td> <td>
    MiniMRCluster mr = null;
    try {
        mr = new MiniMRCluster(2, "file:///", 3);
        // make cleanup inline sothat validation of existence of these directories
        // can be done
        mr.setInlineCleanupThreads();
        TestMiniMRWithDFS.runPI(mr, mr.createJobConf());
        // run the wordcount example with caching
        JobConf job = mr.createJobConf();
        TestResult ret = MRCaching.launchMRCache(TEST_ROOT_DIR + "/wc/input", TEST_ROOT_DIR + "/wc/output", TEST_ROOT_DIR + "/cachedir", job, "The quick brown fox\n" + "has many silly\n" + "red fox sox\n");
        // assert the number of lines read during caching
        assertTrue("Failed test archives not matching", ret.isOutputOk);
        // test the task report fetchers
        JobClient client = new JobClient(job);
        JobID jobid = ret.job.getID();
        TaskReport[] reports;
        reports = client.getSetupTaskReports(jobid);
        assertEquals("number of setups", 2, reports.length);
        reports = client.getMapTaskReports(jobid);
        assertEquals("number of maps", 1, reports.length);
        reports = client.getReduceTaskReports(jobid);
        assertEquals("number of reduces", 1, reports.length);
        reports = client.getCleanupTaskReports(jobid);
        assertEquals("number of cleanups", 2, reports.length);
        Counters counters = ret.job.getCounters();
        assertEquals("number of map inputs", 3, counters.getCounter(TaskCounter.MAP_INPUT_RECORDS));
        assertEquals("number of reduce outputs", 9, counters.getCounter(TaskCounter.REDUCE_OUTPUT_RECORDS));
        runCustomFormats(mr);
        runSecondarySort(mr.createJobConf());
    } finally {
        if (mr != null) {
            mr.shutdown();
        }
    }
</td> </tr></table></body></html>