<html><head>
<style> table, th, td {
  border: 1px solid black;
  border-collapse: collapse;
}th {
  background: lightblue;
}</style>
</head> <body><h1>SATD</h1><table><tr><th>satd id</th> <th>satd instance id</th>  <th>project</th> <th>committer name </th> <th> Commit Hash</th> <th>old comment</th> <th>New Comment</th> <th>resolution</th> <th>Method Signature</th> <th>Method Declaration</th> <th>Method Body</th> </tr><tr><td>5011</td> <td>-1009652563</td><td>apache/hadoop</td><td>Owen O'Malley</td><td>95a0db602b2e0606af11d666d9d10d64766f9ecf</td> <td>None</td> <td>Refresh the service level authorization policy once again,
this time it should fail!</td> <td>SATD_ADDED</td> <td>testRefresh()</td> <td>public void testRefresh() throws Exception</td> <td>
    MiniDFSCluster dfs = null;
    try {
        final int slaves = 4;
        // Turn on service-level authorization
        Configuration conf = new Configuration();
        conf.setClass(PolicyProvider.POLICY_PROVIDER_CONFIG, HDFSPolicyProvider.class, PolicyProvider.class);
        conf.setBoolean(ServiceAuthorizationManager.SERVICE_AUTHORIZATION_CONFIG, true);
        // Start the mini dfs cluster
        dfs = new MiniDFSCluster(conf, slaves, true, null);
        // Refresh the service level authorization policy
        refreshPolicy(conf);
        // Simulate an 'edit' of hadoop-policy.xml
        String confDir = System.getProperty("test.build.extraconf", "build/test/extraconf");
        File policyFile = new File(confDir, ConfiguredPolicy.HADOOP_POLICY_FILE);
        String policyFileCopy = ConfiguredPolicy.HADOOP_POLICY_FILE + ".orig";
        // first save original
        FileUtil.copy(// first save original
        policyFile, // first save original
        FileSystem.getLocal(conf), new Path(confDir, policyFileCopy), false, conf);
        rewriteHadoopPolicyFile(new File(confDir, ConfiguredPolicy.HADOOP_POLICY_FILE));
        // Refresh the service level authorization policy
        refreshPolicy(conf);
        // Refresh the service level authorization policy once again,
        // this time it should fail!
        try {
            // Note: hadoop-policy.xml for tests has
            // security.refresh.policy.protocol.acl = ${user.name}
            conf.set(UnixUserGroupInformation.UGI_PROPERTY_NAME, UNKNOWN_USER);
            refreshPolicy(conf);
            fail("Refresh of NameNode's policy file cannot be successful!");
        } catch (RemoteException re) {
            System.out.println("Good, refresh worked... refresh failed with: " + StringUtils.stringifyException(re.unwrapRemoteException()));
        } finally {
            // Reset to original hadoop-policy.xml
            FileUtil.fullyDelete(new File(confDir, ConfiguredPolicy.HADOOP_POLICY_FILE));
            FileUtil.replaceFile(new File(confDir, policyFileCopy), new File(confDir, ConfiguredPolicy.HADOOP_POLICY_FILE));
        }
    } finally {
        if (dfs != null) {
            dfs.shutdown();
        }
    }
</td> </tr></table></body></html>