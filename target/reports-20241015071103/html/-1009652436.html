<html><head>
<style> table, th, td {
  border: 1px solid black;
  border-collapse: collapse;
}th {
  background: lightblue;
}</style>
</head> <body><h1>SATD</h1><table><tr><th>satd id</th> <th>satd instance id</th>  <th>project</th> <th>committer name </th> <th> Commit Hash</th> <th>old comment</th> <th>New Comment</th> <th>resolution</th> <th>Method Signature</th> <th>Method Declaration</th> <th>Method Body</th> </tr><tr><td>5286</td> <td>-1009652436</td><td>apache/hadoop</td><td>Eli Collins</td><td>a196766ea07775f18ded69bd9e8d239f8cfd3ccc</td> <td>None</td> <td>Checking if a Mapper.map within a Runnable has generated an
IOException. If so we rethrow it to force an abort of the Map
operation thus keeping the semantics of the default
implementation.</td> <td>SATD_ADDED</td> <td>configure(JobConf)</td> <td>public void configure(JobConf jobConf)</td> <td>
    int numberOfThreads = jobConf.getInt(MultithreadedMapper.NUM_THREADS, 10);
    if (LOG.isDebugEnabled()) {
        LOG.debug("Configuring jobConf " + jobConf.getJobName() + " to use " + numberOfThreads + " threads");
    }
    this.job = jobConf;
    // increment processed counter only if skipping feature is enabled
    this.incrProcCount = SkipBadRecords.getMapperMaxSkipRecords(job) > 0 && SkipBadRecords.getAutoIncrMapperProcCount(job);
    this.mapper = ReflectionUtils.newInstance(jobConf.getMapperClass(), jobConf);
    // Creating a threadpool of the configured size to execute the Mapper
    // map method in parallel.
    executorService = new ThreadPoolExecutor(numberOfThreads, numberOfThreads, 0L, TimeUnit.MILLISECONDS, new BlockingArrayQueue(numberOfThreads));
</td> </tr></table></body></html>